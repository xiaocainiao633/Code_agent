# LLM提供商配置
# 可选: ollama, openai, anthropic, deepseek, kimi
LLM_PROVIDER=deepseek

# Ollama配置 (本地)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# OpenAI配置
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_BASE_URL=https://api.openai.com/v1  # 可选，用于代理

# Anthropic配置
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307

# DeepSeek配置 (推荐 - 性价比高)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com

# Kimi配置 (月之暗面 - 中文表现优秀)
KIMI_API_KEY=your_kimi_api_key_here
KIMI_MODEL=moonshot-v1-8k
KIMI_BASE_URL=https://api.moonshot.cn/v1

# 通用LLM配置
LLM_MAX_TOKENS=2000
LLM_TEMPERATURE=0.1
LLM_TIMEOUT=30
LLM_RETRY_COUNT=3

# FastAPI配置
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=true

# ChromaDB配置
CHROMA_PERSIST_DIRECTORY=./chroma_db
CHROMA_COLLECTION_NAME=code_embeddings

# 日志配置
LOG_LEVEL=INFO
LOG_FILE=./logs/app.log

# 安全配置
MAX_CODE_SIZE=1048576  # 1MB
ALLOWED_FILE_EXTENSIONS=.py,.js,.java,.cpp,.c